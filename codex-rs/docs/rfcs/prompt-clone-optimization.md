# RFC: æ¶ˆé™¤ Prompt Clone - RequestContext é‡æ„æ–¹æ¡ˆ

**çŠ¶æ€**: Draft
**åˆ›å»ºæ—¶é—´**: 2025-11-21
**ä½œè€…**: Claude (åŸºäºç”¨æˆ·éœ€æ±‚åˆ†æ)
**å½±å“èŒƒå›´**: core/client.rs, core/adapters/, codex.rs

---

## ğŸ“‹ ç›®å½•

1. [èƒŒæ™¯å’Œé—®é¢˜](#èƒŒæ™¯å’Œé—®é¢˜)
2. [ä¼˜åŒ–ç›®æ ‡](#ä¼˜åŒ–ç›®æ ‡)
3. [æŠ€æœ¯å†³ç­–](#æŠ€æœ¯å†³ç­–)
4. [æ•°æ®æµåˆ†æ](#æ•°æ®æµåˆ†æ)
5. [æœ€ç»ˆæ–¹æ¡ˆ](#æœ€ç»ˆæ–¹æ¡ˆ)
6. [è¯¦ç»†å®æ–½æ­¥éª¤](#è¯¦ç»†å®æ–½æ­¥éª¤)
7. [éªŒè¯æ¸…å•](#éªŒè¯æ¸…å•)
8. [æ€§èƒ½å¯¹æ¯”](#æ€§èƒ½å¯¹æ¯”)
9. [å­˜åœ¨ä¸è¶³](#å­˜åœ¨ä¸è¶³)
10. [æœªæ¥ä¼˜åŒ–](#æœªæ¥ä¼˜åŒ–)

---

## èƒŒæ™¯å’Œé—®é¢˜

### å½“å‰æ¶æ„é—®é¢˜

åœ¨å½“å‰çš„ LLM è°ƒç”¨æµç¨‹ä¸­ï¼Œå­˜åœ¨ä¸€ä¸ªæ€§èƒ½ç“¶é¢ˆï¼š

```rust
// http.rs:99-105 (å½“å‰å®ç°)
let mut enhanced_prompt = prompt.clone();  // âŒ å…‹éš†æ•´ä¸ª Prompt
enhanced_prompt.reasoning_effort = effort;
enhanced_prompt.reasoning_summary = Some(summary);

adapter.transform_request(&enhanced_prompt, provider)
```

**é—®é¢˜åˆ†æï¼š**

1. **å¤§å¯¹è±¡å…‹éš†**ï¼š`Prompt` åŒ…å« `input: Vec<ResponseItem>`ï¼ˆå®Œæ•´æ¶ˆæ¯å†å²ï¼‰
2. **å…‹éš†æˆæœ¬**ï¼š
   - å°å¯¹è¯ï¼ˆ10æ¡æ¶ˆæ¯ï¼‰ï¼š~5 KB
   - ä¸­ç­‰å¯¹è¯ï¼ˆ50æ¡æ¶ˆæ¯ï¼‰ï¼š~25 KB
   - å¤§å¯¹è¯ï¼ˆ200æ¡æ¶ˆæ¯ï¼‰ï¼š~100 KB
   - è¶…å¤§å¯¹è¯ï¼ˆ1000æ¡+ï¼‰ï¼š~500 KB
3. **å…‹éš†åŸå› **ï¼šéœ€è¦æ³¨å…¥ `reasoning_effort` å’Œ `reasoning_summary`ï¼Œä½† `transform_request` æ¥å£æ˜¯åªè¯»çš„ï¼ˆ`&Prompt`ï¼‰
4. **å¹´åº¦æˆæœ¬**ï¼ˆå‡è®¾ 1M å¯¹è¯ï¼Œå¹³å‡ 100 KBï¼‰ï¼š
   - ä¿®æ”¹å‰ï¼š`1M Ã— 100 KB Ã— 3 turns = 300 GB` å†…å­˜åˆ†é…

### æ ¹æœ¬åŸå› 

**æ¶æ„ç¼ºé™·ï¼š** Prompt æ··åˆäº†ä¸¤ç§ä¸åŒç”Ÿå‘½å‘¨æœŸçš„æ•°æ®ï¼š

| æ•°æ®ç±»å‹ | ç”Ÿå‘½å‘¨æœŸ | å˜åŒ–é¢‘ç‡ | å¤§å° |
|---------|---------|---------|------|
| **æ¶ˆæ¯å†å²** (input) | Per-turn ç´¯ç§¯ | æ¯ turn å¢é•¿ | 5-500 KB |
| **é…ç½®å‚æ•°** (4 å­—æ®µ) | Per-turn å˜åŒ– | å¯èƒ½æ¯ turn å˜åŒ– | ~100 bytes |

**4 ä¸ªé…ç½®å­—æ®µï¼š**
1. `reasoning_effort: Option<ReasoningEffortConfig>` - æ¨ç†å¼ºåº¦
2. `reasoning_summary: Option<ReasoningSummaryConfig>` - æ¨ç†æ‘˜è¦é…ç½®
3. `previous_response_id: Option<String>` - å¢é‡å¯¹è¯ ID
4. `effective_parameters: ModelParameters` - é‡‡æ ·å‚æ•°ï¼ˆtemperature, top_p ç­‰ï¼‰

---

## ä¼˜åŒ–ç›®æ ‡

### ä¸»è¦ç›®æ ‡

1. âœ… **æ¶ˆé™¤å¤§å¯¹è±¡å…‹éš†** - åªå¤åˆ¶å°é…ç½®å¯¹è±¡ï¼ˆ~100 bytesï¼‰
2. âœ… **æ•°æ®èŒè´£åˆ†ç¦»** - Prompt ä¸“æ³¨æ¶ˆæ¯ï¼ŒRequestContext è´Ÿè´£é…ç½®
3. âœ… **æœ€å° API å˜æ›´** - å°½é‡ä¿æŒå‘åå…¼å®¹
4. âœ… **è¯­ä¹‰æ¸…æ™°åŒ–** - ç»Ÿä¸€"è¯·æ±‚ä¸Šä¸‹æ–‡"æ¦‚å¿µ

### æ€§èƒ½æŒ‡æ ‡

- **å…‹éš†å¼€é”€é™ä½**ï¼š98-99.9%
- **å¹´åº¦èŠ‚çœ**ï¼ˆ1M å¯¹è¯ï¼‰ï¼š~300 GB â†’ ~300 MB
- **å•æ¬¡ turn å»¶è¿Ÿ**ï¼šå‡å°‘ 0.1-1 msï¼ˆå†…å­˜åˆ†é…å¼€é”€ï¼‰

---

## æŠ€æœ¯å†³ç­–

### å†³ç­– 1ï¼šå¤ç”¨ç°æœ‰ RequestContext

**é€‰é¡¹ A**ï¼šæ–°å»º `TransformContext` ç»“æ„ä½“
**é€‰é¡¹ B**ï¼šæ‰©å±•ç°æœ‰ `RequestContext`ï¼ˆâœ… é€‰æ‹©ï¼‰

**ç†ç”±ï¼š**
- RequestContext å·²å­˜åœ¨ï¼Œç”¨äºä¼ é€’è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼ˆconversation_id, session_sourceï¼‰
- æ‰©å±•åè¯­ä¹‰æ›´ç»Ÿä¸€ï¼š"è¯·æ±‚ä¸Šä¸‹æ–‡" = è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ + æ¨¡å‹é…ç½®å‚æ•°
- å‡å°‘æ–°ç±»å‹ï¼Œé™ä½è®¤çŸ¥è´Ÿæ‹…
- `build_request_metadata` å·²ä½¿ç”¨ RequestContextï¼Œä¿æŒä¸€è‡´

### å†³ç­– 2ï¼šä» Prompt å®Œå…¨ç§»é™¤ 4 ä¸ªå­—æ®µ

**é€‰é¡¹ A**ï¼šPrompt ä¿ç•™å­—æ®µï¼Œç”¨ `Arc<RequestContext>` ä¼˜åŒ–
**é€‰é¡¹ B**ï¼šå®Œå…¨ç§»é™¤å­—æ®µï¼Œåˆ†ç¦» Prompt å’Œ RequestContextï¼ˆâœ… é€‰æ‹©ï¼‰

**ç†ç”±ï¼š**
- æ¸…æ™°çš„èŒè´£åˆ†ç¦»ï¼šPromptï¼ˆä¸å¯å˜æ¶ˆæ¯ï¼‰ vs RequestContextï¼ˆå¯å˜é…ç½®ï¼‰
- é¿å…æ•°æ®é‡å¤ï¼šåŒä¸€é…ç½®ä¸åº”åŒæ—¶å­˜åœ¨äº Prompt å’Œ RequestContext
- æ›´ç¬¦åˆ Rust æƒ¯ç”¨æ³•ï¼šä¸å¯å˜æ•°æ® + æ˜¾å¼ä¸Šä¸‹æ–‡
- ä¸ºæœªæ¥æ‰©å±•é“ºè·¯ï¼ˆå¦‚æ·»åŠ æ–°é…ç½®å‚æ•°ï¼‰

### å†³ç­– 3ï¼šclient.stream() å¢åŠ å‚æ•°

**é€‰é¡¹ A**ï¼šä¿æŒç­¾åä¸å˜ï¼Œå†…éƒ¨ä» self + prompt ç»„è£…
**é€‰é¡¹ B**ï¼šå¢åŠ  `previous_response_id` å‚æ•°ï¼ˆâœ… é€‰æ‹©ï¼‰

**ç†ç”±ï¼š**
- `previous_response_id` æ˜¯ per-turn åŠ¨æ€çŠ¶æ€ï¼Œä¸å±äº ModelClient
- `effective_parameters` å¯ä»¥ä» `self.resolve_parameters()` è·å–
- åªå¢åŠ  1 ä¸ªå‚æ•°ï¼ŒAPI å˜æ›´æœ€å°
- æ•°æ®æµæ›´æ¸…æ™°ï¼šSessionState â†’ codex.rs â†’ client.stream()

### å†³ç­– 4ï¼šstream_with_adapter å‚æ•°ç®€åŒ–

**å½“å‰ç­¾å**ï¼š8 ä¸ªå‚æ•°
**ä¼˜åŒ–å**ï¼š5 ä¸ªå‚æ•°ï¼ˆâœ… åˆå¹¶ä¸º RequestContextï¼‰

**å‚æ•°å˜åŒ–ï¼š**
```rust
// åˆ é™¤è¿™ 6 ä¸ªç‹¬ç«‹å‚æ•°ï¼š
conversation_id: ConversationId,
session_source: SessionSource,
effort: Option<ReasoningEffortConfig>,
summary: ReasoningSummaryConfig,
// ä»¥åŠä» prompt è¯»å–çš„ï¼š
// previous_response_id, effective_parameters

// æ›¿æ¢ä¸º 1 ä¸ªå‚æ•°ï¼š
context: RequestContext  // åŒ…å«å…¨éƒ¨ 6 ä¸ªå­—æ®µ
```

---

## æ•°æ®æµåˆ†æ

### å½“å‰æ•°æ®æµï¼ˆæœ‰é—®é¢˜ï¼‰

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ codex.rs:1959 - æ„é€  Promptï¼ˆåŒ…å« 4 å­—æ®µï¼‰                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”œâ”€ previous_response_id = sess.state.get_last_response()
  â”œâ”€ effective_parameters = client.resolve_parameters()
  â””â”€ prompt = Prompt {
        input,
        tools,
        previous_response_id,     // âŒ å¤§å¯¹è±¡ä¸­åµŒå…¥å°å­—æ®µ
        effective_parameters,     // âŒ
        reasoning_effort: None,   // âŒ é»˜è®¤å€¼ï¼Œåç»­å…‹éš†æ³¨å…¥
        reasoning_summary: None,  // âŒ
      }
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ client.rs:180 - client.stream(&prompt)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”œâ”€ ä» self è¯»å–ï¼šeffort, summary
  â””â”€ ä» prompt è¯»å–ï¼šprevious_response_id, effective_parameters
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ http.rs:99 - stream_with_adapter(prompt, ..., effort, ...)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”œâ”€ let mut enhanced_prompt = prompt.clone();  // âŒ å…‹éš† Vec<ResponseItem>
  â”œâ”€ enhanced_prompt.reasoning_effort = effort;
  â””â”€ enhanced_prompt.reasoning_summary = Some(summary);
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ adapter.transform_request(&enhanced_prompt, provider)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  è¯»å–æ‰€æœ‰ 4 å­—æ®µ
```

**é—®é¢˜ç‚¹ï¼š**
1. Prompt åŒ…å«ä¸å¿…è¦çš„å­—æ®µï¼ˆreasoning_effort/summary é»˜è®¤ä¸º Noneï¼‰
2. éœ€è¦ clone æ•´ä¸ª Prompt æ‰èƒ½æ³¨å…¥è¿™ 2 ä¸ªå­—æ®µ
3. æ•°æ®æµæ··ä¹±ï¼š4 å­—æ®µæ¥è‡ªä¸åŒæ¥æºï¼Œä½†å…¨éƒ¨å¡è¿› Prompt

### ä¼˜åŒ–åæ•°æ®æµ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ codex.rs:1959 - åˆ†ç¦»æ„é€  Prompt å’Œ previous_response_id  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â”œâ”€ previous_response_id = sess.state.get_last_response()
  â””â”€ prompt = Prompt {
        input,
        tools,
        parallel_tool_calls,
        base_instructions_override,
        output_schema,
      }  // âœ… ä¸å« 4 å­—æ®µï¼Œä¸“æ³¨æ¶ˆæ¯
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ client.rs:180 - client.stream(&prompt, previous_response_id)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  âœ… æ„é€ å®Œæ•´ RequestContextï¼ˆ6 å­—æ®µï¼‰ï¼š
  â”œâ”€ conversation_id: self.conversation_id
  â”œâ”€ session_source: self.session_source
  â”œâ”€ reasoning_effort: self.effort              // ä» ModelClient
  â”œâ”€ reasoning_summary: Some(self.summary)      // ä» ModelClient
  â”œâ”€ effective_parameters: self.resolve_parameters()  // å†…éƒ¨è°ƒç”¨
  â””â”€ previous_response_id                       // ä»å‚æ•°
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ http.rs - stream_with_adapter(prompt, context, ...)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  âœ… ç›´æ¥ä¼ é€’ï¼Œæ— éœ€ cloneï¼š
  â”œâ”€ adapter.transform_request(prompt, &context, provider)
  â””â”€ adapter.build_request_metadata(prompt, &context, provider)
  â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ adapter - ä» context è¯»å–æ‰€æœ‰é…ç½®                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  context.reasoning_effort
  context.reasoning_summary
  context.previous_response_id
  context.effective_parameters
  context.conversation_id        // è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
  context.session_source         // è¿è¡Œæ—¶ä¸Šä¸‹æ–‡
```

**æ”¹è¿›ç‚¹ï¼š**
1. âœ… Prompt ä¸“æ³¨æ¶ˆæ¯å†å²ï¼Œä½“ç§¯ä¸å˜ä½†ä¸å«å†—ä½™å­—æ®µ
2. âœ… RequestContext é›†ä¸­ç®¡ç†æ‰€æœ‰é…ç½®å‚æ•°
3. âœ… é›¶ clone - åªå¤åˆ¶ 6 ä¸ªå°å­—æ®µï¼ˆ~100 bytesï¼‰
4. âœ… æ•°æ®æµæ¸…æ™°ï¼šæ¯ä¸ªå­—æ®µæ¥æºæ˜ç¡®

### 4 ä¸ªå­—æ®µçš„æ•°æ®æ¥æº

| å­—æ®µ | æ¥æº | è·å–ä½ç½® | ç”Ÿå‘½å‘¨æœŸ |
|------|------|---------|---------|
| `reasoning_effort` | Config â†’ ModelClient | client.rs (self.effort) | Per-session |
| `reasoning_summary` | Config â†’ ModelClient | client.rs (self.summary) | Per-session |
| `previous_response_id` | SessionState | codex.rs â†’ client.stream() | Per-turn |
| `effective_parameters` | Config + Provider | client.rs (self.resolve_parameters()) | Per-turn |
| `conversation_id` | ModelClient | client.rs (self.conversation_id) | Per-session |
| `session_source` | ModelClient | client.rs (self.session_source) | Per-session |

**å…³é”®å‘ç°ï¼š**
- `previous_response_id` æ˜¯å”¯ä¸€éœ€è¦ä»å¤–éƒ¨ä¼ å…¥çš„ï¼ˆæ¯ turn å˜åŒ–ï¼‰
- å…¶ä»– 5 ä¸ªå­—æ®µéƒ½å¯ä»¥ä» `ModelClient` å†…éƒ¨è·å–
- å› æ­¤ `client.stream()` åªéœ€å¢åŠ  1 ä¸ªå‚æ•°

---

## æœ€ç»ˆæ–¹æ¡ˆ

### æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RequestContextï¼ˆæ‰©å±•åï¼‰                                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼ˆç°æœ‰ï¼‰                                      â”‚
â”‚ â”œâ”€ conversation_id: String                              â”‚
â”‚ â””â”€ session_source: String                               â”‚
â”‚                                                          â”‚
â”‚ æ¨¡å‹é…ç½®å‚æ•°ï¼ˆæ–°å¢ï¼‰                                      â”‚
â”‚ â”œâ”€ reasoning_effort: Option<ReasoningEffortConfig>     â”‚
â”‚ â”œâ”€ reasoning_summary: Option<ReasoningSummaryConfig>   â”‚
â”‚ â”œâ”€ previous_response_id: Option<String>                â”‚
â”‚ â””â”€ effective_parameters: ModelParameters               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Promptï¼ˆç²¾ç®€åï¼‰                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ ¸å¿ƒæ¶ˆæ¯æ•°æ®                                             â”‚
â”‚ â”œâ”€ input: Vec<ResponseItem>            // æ¶ˆæ¯å†å²      â”‚
â”‚ â”œâ”€ tools: Vec<ToolSpec>                // å¯ç”¨å·¥å…·      â”‚
â”‚ â”œâ”€ parallel_tool_calls: bool           // å¹¶è¡Œè°ƒç”¨      â”‚
â”‚ â”œâ”€ base_instructions_override: Option<String>          â”‚
â”‚ â””â”€ output_schema: Option<Value>        // ç»“æ„åŒ–è¾“å‡º    â”‚
â”‚                                                          â”‚
â”‚ âŒ åˆ é™¤çš„å­—æ®µï¼š                                          â”‚
â”‚ - reasoning_effort                                      â”‚
â”‚ - reasoning_summary                                     â”‚
â”‚ - previous_response_id                                  â”‚
â”‚ - effective_parameters                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ¥å£å˜æ›´

#### 1. RequestContext æ‰©å±•

```rust
#[derive(Debug, Clone)]
pub struct RequestContext {
    // ===== ç°æœ‰å­—æ®µ =====
    pub conversation_id: String,
    pub session_source: String,

    // ===== æ–°å¢å­—æ®µ =====
    pub reasoning_effort: Option<ReasoningEffortConfig>,
    pub reasoning_summary: Option<ReasoningSummaryConfig>,
    pub previous_response_id: Option<String>,
    pub effective_parameters: ModelParameters,
}
```

#### 2. Prompt ç²¾ç®€

```rust
pub struct Prompt {
    pub input: Vec<ResponseItem>,
    pub tools: Vec<ToolSpec>,
    pub parallel_tool_calls: bool,
    pub base_instructions_override: Option<String>,
    pub output_schema: Option<Value>,

    // âŒ åˆ é™¤ï¼šreasoning_effort, reasoning_summary,
    //         previous_response_id, effective_parameters
}
```

#### 3. client.stream() ç­¾å

```rust
// ä¿®æ”¹å‰
pub async fn stream(&self, prompt: &Prompt) -> Result<ResponseStream>

// ä¿®æ”¹åï¼ˆ+1 å‚æ•°ï¼‰
pub async fn stream(
    &self,
    prompt: &Prompt,
    previous_response_id: Option<String>,
) -> Result<ResponseStream>
```

#### 4. stream_with_adapter ç­¾å

```rust
// ä¿®æ”¹å‰ï¼ˆ8 å‚æ•°ï¼‰
pub async fn stream_with_adapter(
    &self,
    prompt: &Prompt,
    provider: &ModelProviderInfo,
    adapter_name: &str,
    conversation_id: ConversationId,
    session_source: SessionSource,
    effort: Option<ReasoningEffortConfig>,
    summary: ReasoningSummaryConfig,
    global_stream_idle_timeout: Option<u64>,
) -> Result<ResponseStream>

// ä¿®æ”¹åï¼ˆ5 å‚æ•°ï¼‰
pub async fn stream_with_adapter(
    &self,
    prompt: &Prompt,
    context: RequestContext,  // æ›¿ä»£ 6 ä¸ªå‚æ•°
    provider: &ModelProviderInfo,
    adapter_name: &str,
    global_stream_idle_timeout: Option<u64>,
) -> Result<ResponseStream>
```

#### 5. ProviderAdapter trait

```rust
pub trait ProviderAdapter: Send + Sync {
    // ä¿®æ”¹å‰
    fn transform_request(
        &self,
        prompt: &Prompt,
        provider: &ModelProviderInfo,
    ) -> Result<JsonValue>;

    // ä¿®æ”¹åï¼ˆ+1 å‚æ•°ï¼‰
    fn transform_request(
        &self,
        prompt: &Prompt,
        context: &RequestContext,
        provider: &ModelProviderInfo,
    ) -> Result<JsonValue>;

    // build_request_metadata ç»Ÿä¸€å‘½å
    fn build_request_metadata(
        &self,
        prompt: &Prompt,
        context: &RequestContext,  // ä¹‹å‰å« runtime_context
        provider: &ModelProviderInfo,
    ) -> Result<RequestMetadata> {
        Ok(RequestMetadata::default())
    }
}
```

---

## è¯¦ç»†å®æ–½æ­¥éª¤

### Phase 1: åŸºç¡€ç»“æ„ä¿®æ”¹

#### Step 1.1: æ‰©å±• RequestContext

**æ–‡ä»¶**: `codex-rs/core/src/adapters/mod.rs`ï¼ˆæˆ– `request_context.rs`ï¼‰
**ä½ç½®**: å¦‚æœæ˜¯ç‹¬ç«‹æ–‡ä»¶ï¼Œåœ¨ `adapters/` ç›®å½•ä¸‹

```rust
use codex_protocol::config_types::ModelParameters;
use codex_protocol::config_types::ReasoningEffort as ReasoningEffortConfig;
use codex_protocol::config_types::ReasoningSummary as ReasoningSummaryConfig;

#[derive(Debug, Clone)]
pub struct RequestContext {
    // ===== ç°æœ‰å­—æ®µï¼ˆè¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼‰=====
    /// Unique identifier for the current conversation
    ///
    /// Used for:
    /// - Request tracking across multiple API calls
    /// - Log correlation in enterprise LLM gateways
    /// - Session identification
    pub conversation_id: String,

    /// Source/origin of the session
    ///
    /// Possible values: "Cli", "VSCode", "Exec", "Mcp", "SubAgent", "Unknown"
    ///
    /// Used for:
    /// - Telemetry headers (x-openai-subagent)
    /// - Source-specific request handling
    /// - Debug/audit trails
    pub session_source: String,

    // ===== æ–°å¢å­—æ®µï¼ˆæ¨¡å‹é…ç½®å‚æ•°ï¼‰=====
    /// Reasoning effort level for models that support extended thinking
    ///
    /// Source: ModelClient.effort (from Config.model_reasoning_effort)
    /// Lifecycle: Per-session (stable across turns)
    ///
    /// Values: None | Low | Medium | High
    pub reasoning_effort: Option<ReasoningEffortConfig>,

    /// Reasoning summary configuration
    ///
    /// Source: ModelClient.summary (from Config.model_reasoning_summary)
    /// Lifecycle: Per-session (stable across turns)
    ///
    /// Controls how reasoning content is presented (Detailed vs Concise)
    pub reasoning_summary: Option<ReasoningSummaryConfig>,

    /// Previous response ID for conversation continuity
    ///
    /// Source: SessionState.get_last_response() (updated each turn)
    /// Lifecycle: Per-turn (dynamic)
    ///
    /// Used for incremental conversation mode to reduce payload size
    pub previous_response_id: Option<String>,

    /// Resolved model sampling parameters
    ///
    /// Source: ModelClient.resolve_parameters()
    ///         (merged from Config + ModelProviderInfo overrides)
    /// Lifecycle: Per-turn (may change if provider config changes)
    ///
    /// Contains: temperature, top_p, frequency_penalty,
    ///           presence_penalty, max_tokens
    pub effective_parameters: ModelParameters,
}
```

**æ¨¡å—æ³¨å†Œ**ï¼ˆå¦‚æœæ˜¯ç‹¬ç«‹æ–‡ä»¶ï¼‰:
```rust
// In adapters/mod.rs
mod request_context;
pub use request_context::RequestContext;
```

#### Step 1.2: ç²¾ç®€ Prompt ç»“æ„

**æ–‡ä»¶**: `codex-rs/core/src/client_common.rs`
**ä½ç½®**: line 31-66

**åˆ é™¤å­—æ®µ**:
```rust
pub struct Prompt {
    pub input: Vec<ResponseItem>,
    pub tools: Vec<ToolSpec>,
    pub parallel_tool_calls: bool,
    pub base_instructions_override: Option<String>,
    pub output_schema: Option<Value>,

    // âŒ åˆ é™¤ä»¥ä¸‹ 4 ä¸ªå­—æ®µï¼š
    // pub reasoning_effort: Option<ReasoningEffortConfig>,
    // pub reasoning_summary: Option<ReasoningSummaryConfig>,
    // pub previous_response_id: Option<String>,
    // pub effective_parameters: ModelParameters,
}
```

**æ›´æ–° Default å®ç°**:
```rust
impl Default for Prompt {
    fn default() -> Self {
        Self {
            input: Vec::new(),
            tools: Vec::new(),
            parallel_tool_calls: false,
            base_instructions_override: None,
            output_schema: None,
            // âŒ åˆ é™¤ï¼š
            // reasoning_effort: None,
            // reasoning_summary: None,
            // previous_response_id: None,
            // effective_parameters: Default::default(),
        }
    }
}
```

### Phase 2: æ›´æ–° Trait å’Œæ¥å£

#### Step 2.1: æ›´æ–° ProviderAdapter trait

**æ–‡ä»¶**: `codex-rs/core/src/adapters/mod.rs`
**ä½ç½®**: line 431-460

```rust
pub trait ProviderAdapter: Send + Sync {
    /// Transform prompt and context into provider-specific request format
    ///
    /// # Parameters
    /// - `prompt`: Message history and tool specs
    /// - `context`: Request configuration (reasoning, parameters, etc.)
    /// - `provider`: Provider-specific settings
    fn transform_request(
        &self,
        prompt: &Prompt,
        context: &RequestContext,  // âœ… æ–°å¢å‚æ•°
        provider: &ModelProviderInfo,
    ) -> Result<JsonValue>;

    /// Build dynamic request metadata (headers, query params)
    ///
    /// # Parameters
    /// - `prompt`: Message history (rarely used by this method)
    /// - `context`: Full request context (conversation_id, session_source, etc.)
    /// - `provider`: Provider-specific settings
    fn build_request_metadata(
        &self,
        prompt: &Prompt,
        context: &RequestContext,  // âœ… ç»Ÿä¸€å‘½åï¼ˆä¹‹å‰å« runtime_contextï¼‰
        provider: &ModelProviderInfo,
    ) -> Result<RequestMetadata> {
        // Default: no extra headers/params
        let _ = (prompt, context, provider);
        Ok(RequestMetadata::default())
    }

    // ... å…¶ä»–æ–¹æ³•ä¿æŒä¸å˜
}
```

#### Step 2.2: æ›´æ–° client.stream()

**æ–‡ä»¶**: `codex-rs/core/src/client.rs`
**ä½ç½®**: line 180-240

**ä¿®æ”¹ç­¾å**:
```rust
pub async fn stream(
    &self,
    prompt: &Prompt,
    previous_response_id: Option<String>,  // âœ… æ–°å¢å‚æ•°
) -> Result<ResponseStream>
```

**ä¿®æ”¹å‡½æ•°ä½“**ï¼ˆadapter åˆ†æ”¯ï¼‰:
```rust
pub async fn stream(
    &self,
    prompt: &Prompt,
    previous_response_id: Option<String>,
) -> Result<ResponseStream> {
    // Check if provider specifies a custom adapter
    if let Some(adapter_name) = &self.provider.adapter {
        // ğŸ”‘ æ ¸å¿ƒæ”¹åŠ¨ï¼šåœ¨è¿™é‡Œæ„é€ å®Œæ•´ RequestContext
        let context = RequestContext {
            // è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ï¼ˆä» selfï¼‰
            conversation_id: self.conversation_id.to_string(),
            session_source: format!("{:?}", self.session_source),

            // æ¨¡å‹é…ç½®å‚æ•°ï¼ˆä» selfï¼‰
            reasoning_effort: self.effort,
            reasoning_summary: Some(self.summary),
            effective_parameters: self.resolve_parameters(),  // å†…éƒ¨è°ƒç”¨

            // ä¼šè¯çŠ¶æ€ï¼ˆä»å‚æ•°ï¼‰
            previous_response_id,
        };

        let adapter_client = AdapterHttpClient::new(
            self.client.clone(),
            self.otel_event_manager.clone(),
        );

        return adapter_client
            .stream_with_adapter(
                prompt,
                context,  // âœ… å•ä¸ªå‚æ•°æ›¿ä»£ 6 ä¸ªç‹¬ç«‹å‚æ•°
                &self.provider,
                adapter_name,
                self.config.stream_idle_timeout_ms,
            )
            .await;
    }

    // Fallback to existing wire_api routing (backward compatible)
    match self.provider.wire_api {
        WireApi::Responses => self.stream_responses(prompt, previous_response_id).await,
        WireApi::Chat => {
            // Chat completions API å¯èƒ½ä¹Ÿéœ€è¦ previous_response_id
            // å½“å‰å®ç°ä¸­æœªä½¿ç”¨ï¼Œä¿æŒä¸å˜
            // ...
        }
    }
}
```

**ä¿®æ”¹ stream_responses**ï¼ˆfallback è·¯å¾„ï¼‰:
```rust
async fn stream_responses(
    &self,
    prompt: &Prompt,
    previous_response_id: Option<String>,  // âœ… æ–°å¢å‚æ•°
) -> Result<ResponseStream> {
    // ... ç°æœ‰é€»è¾‘

    // æ³¨æ„ï¼šå½“å‰ ResponsesApiRequest æ²¡æœ‰ç›´æ¥ä½¿ç”¨ previous_response_id
    // å¦‚æœæœªæ¥éœ€è¦æ”¯æŒï¼Œåœ¨è¿™é‡Œæ·»åŠ 

    // ... rest of the function
}
```

### Phase 3: æ›´æ–° Adapter å®ç°

#### Step 3.1: æ›´æ–° stream_with_adapter

**æ–‡ä»¶**: `codex-rs/core/src/adapters/http.rs`
**ä½ç½®**: line 69-136

**ä¿®æ”¹ç­¾å**ï¼ˆå‚æ•°ä» 8 ä¸ªå‡å°‘åˆ° 5 ä¸ªï¼‰:
```rust
pub async fn stream_with_adapter(
    &self,
    prompt: &Prompt,
    context: RequestContext,  // âœ… æ›¿ä»£ 6 ä¸ªç‹¬ç«‹å‚æ•°
    provider: &ModelProviderInfo,
    adapter_name: &str,
    global_stream_idle_timeout: Option<u64>,
) -> Result<ResponseStream>
```

**ä¿®æ”¹å‡½æ•°ä½“**:

**åˆ é™¤è¿™æ®µ clone é€»è¾‘**ï¼ˆline 98-101ï¼‰:
```rust
// âŒ DELETE: Clone prompt and inject reasoning configuration
let mut enhanced_prompt = prompt.clone();
enhanced_prompt.reasoning_effort = effort;
enhanced_prompt.reasoning_summary = Some(summary);
```

**ä¿®æ”¹ transform_request è°ƒç”¨**ï¼ˆline 103-110ï¼‰:
```rust
// âœ… NEW: Use context directly, no clone needed
let transformed_request = adapter
    .transform_request(prompt, &context, provider)  // ä¼ é€’ context
    .map_err(|e| {
        CodexErr::Fatal(format!(
            "Adapter '{adapter_name}' failed to transform request: {e}"
        ))
    })?;
```

**åˆ é™¤ç‹¬ç«‹æ„é€  request_context**ï¼ˆline 112-116ï¼‰:
```rust
// âŒ DELETE: Build runtime context for dynamic headers/params
let request_context = crate::adapters::RequestContext {
    conversation_id: conversation_id.to_string(),
    session_source: format!("{session_source:?}"),
};
```

**ä¿®æ”¹ build_request_metadata è°ƒç”¨**ï¼ˆline 119-125ï¼‰:
```rust
// âœ… NEW: Reuse the same context
let request_metadata = adapter
    .build_request_metadata(prompt, &context, provider)  // å¤ç”¨ context
    .map_err(|e| {
        CodexErr::Fatal(format!(
            "Adapter '{adapter_name}' failed to build request metadata: {e}"
        ))
    })?;
```

#### Step 3.2: æ›´æ–° GptOpenapiAdapter

**æ–‡ä»¶**: `codex-rs/core/src/adapters/gpt_openapi.rs`
**ä½ç½®**: line 427-470

**ä¿®æ”¹ transform_request ç­¾å**:
```rust
fn transform_request(
    &self,
    prompt: &Prompt,
    context: &RequestContext,  // âœ… æ–°å¢å‚æ•°
    provider: &ModelProviderInfo,
) -> Result<JsonValue>
```

**å…¨å±€æ›¿æ¢å­—æ®µè¯»å–**ï¼ˆåœ¨ transform_request å‡½æ•°å†…ï¼‰:

**Step 1**: æ‰¾åˆ°æ‰€æœ‰ `prompt.effective_parameters` è¯»å–:
```rust
// âŒ ä¿®æ”¹å‰
if let Some(temp) = prompt.effective_parameters.temperature {
    params.insert("temperature", json!(temp));
}
if let Some(top_p) = prompt.effective_parameters.top_p {
    params.insert("top_p", json!(top_p));
}
if let Some(freq) = prompt.effective_parameters.frequency_penalty {
    params.insert("frequency_penalty", json!(freq));
}
if let Some(pres) = prompt.effective_parameters.presence_penalty {
    params.insert("presence_penalty", json!(pres));
}
if let Some(max_tok) = prompt.effective_parameters.max_tokens {
    params.insert("max_tokens", json!(max_tok));
}

// âœ… ä¿®æ”¹å
if let Some(temp) = context.effective_parameters.temperature {
    params.insert("temperature", json!(temp));
}
if let Some(top_p) = context.effective_parameters.top_p {
    params.insert("top_p", json!(top_p));
}
if let Some(freq) = context.effective_parameters.frequency_penalty {
    params.insert("frequency_penalty", json!(freq));
}
if let Some(pres) = context.effective_parameters.presence_penalty {
    params.insert("presence_penalty", json!(pres));
}
if let Some(max_tok) = context.effective_parameters.max_tokens {
    params.insert("max_tokens", json!(max_tok));
}
```

**Step 2**: æ‰¾åˆ° `prompt.previous_response_id` è¯»å–:
```rust
// âŒ ä¿®æ”¹å‰ï¼ˆline 459-460ï¼‰
if let Some(resp_id) = &prompt.previous_response_id {
    params.insert("previous_response_id", json!(resp_id));
}

// âœ… ä¿®æ”¹å
if let Some(resp_id) = &context.previous_response_id {
    params.insert("previous_response_id", json!(resp_id));
}
```

**Step 3**: æ‰¾åˆ° `prompt.reasoning_effort` å’Œ `prompt.reasoning_summary` è¯»å–:
```rust
// âŒ ä¿®æ”¹å‰ï¼ˆline 464-467ï¼‰
if let Some(effort) = prompt.reasoning_effort {
    // ... reasoning é…ç½®é€»è¾‘
}
if let Some(summary) = prompt.reasoning_summary {
    // ...
}

// âœ… ä¿®æ”¹å
if let Some(effort) = context.reasoning_effort {
    // ... reasoning é…ç½®é€»è¾‘
}
if let Some(summary) = context.reasoning_summary {
    // ...
}
```

**è¾…åŠ©ï¼šå…¨å±€æœç´¢å‘½ä»¤**:
```bash
# åœ¨ gpt_openapi.rs ä¸­æŸ¥æ‰¾æ‰€æœ‰éœ€è¦æ›¿æ¢çš„ä½ç½®
rg "prompt\.(effective_parameters|previous_response_id|reasoning_effort|reasoning_summary)" \
   codex-rs/core/src/adapters/gpt_openapi.rs --line-number
```

### Phase 4: æ›´æ–°è°ƒç”¨æ–¹

#### Step 4.1: æ›´æ–° codex.rs æ„é€  Prompt

**æ–‡ä»¶**: `codex-rs/core/src/codex.rs`
**ä½ç½®**: line 1939-1968

**ä¿®æ”¹å‰**:
```rust
let previous_response_id = sess
    .state
    .lock()
    .await
    .get_last_response()
    .map(|id| id.to_string());

let effective_parameters = turn_context.client.resolve_parameters();

let prompt = Prompt {
    input,
    tools: router.specs(),
    parallel_tool_calls,
    base_instructions_override: turn_context.base_instructions.clone(),
    output_schema: turn_context.final_output_json_schema.clone(),
    effective_parameters,        // âŒ åˆ é™¤
    previous_response_id,        // âŒ åˆ é™¤
    reasoning_effort: None,      // âŒ åˆ é™¤
    reasoning_summary: None,     // âŒ åˆ é™¤
};
```

**ä¿®æ”¹å**:
```rust
// æå– previous_response_idï¼ˆéœ€è¦ä¼ é€’ç»™ client.streamï¼‰
let previous_response_id = sess
    .state
    .lock()
    .await
    .get_last_response()
    .map(|id| id.to_string());

// æ„é€  Promptï¼ˆç²¾ç®€ç‰ˆï¼Œä¸å« 4 å­—æ®µï¼‰
let prompt = Prompt {
    input,
    tools: router.specs(),
    parallel_tool_calls,
    base_instructions_override: turn_context.base_instructions.clone(),
    output_schema: turn_context.final_output_json_schema.clone(),
    // âœ… ä¸å†åŒ…å« 4 ä¸ªå­—æ®µ
};
```

#### Step 4.2: æ›´æ–° client.stream() è°ƒç”¨

**æœç´¢æ‰€æœ‰è°ƒç”¨ç‚¹**:
```bash
rg "\.stream\(&prompt\)" codex-rs/core/src --type rust --line-number
rg "client\.stream\(" codex-rs/core/src --type rust -A 2
```

**å…¸å‹è°ƒç”¨ä½ç½®**ï¼ˆéœ€è¦æ ¹æ®å®é™…æœç´¢ç»“æœç¡®è®¤ï¼‰:

å¯èƒ½åœ¨ `try_run_turn` æˆ–ç›´æ¥åœ¨ `run_turn` å‡½æ•°ä¸­ï¼š

**ä¿®æ”¹å‰**:
```rust
let response_stream = turn_context.client.stream(&prompt).await?;
```

**ä¿®æ”¹å**:
```rust
let response_stream = turn_context
    .client
    .stream(&prompt, previous_response_id)
    .await?;
```

**æ³¨æ„äº‹é¡¹**:
- `previous_response_id` å˜é‡éœ€è¦åœ¨è°ƒç”¨å‰å®šä¹‰
- å¦‚æœåœ¨ä¸åŒä½œç”¨åŸŸï¼Œå¯èƒ½éœ€è¦ clone æˆ–é‡æ–°è·å–
- ç¡®ä¿æ‰€æœ‰è°ƒç”¨ç‚¹éƒ½æ›´æ–°ï¼ˆåŒ…æ‹¬æµ‹è¯•æ–‡ä»¶ï¼‰

### Phase 5: æ›´æ–°æµ‹è¯•ä»£ç 

#### Step 5.1: æ›´æ–°å•å…ƒæµ‹è¯•ä¸­çš„ Prompt æ„é€ 

**å½±å“æ–‡ä»¶**: `codex-rs/core/tests/**/*.rs`

**æœç´¢å‘½ä»¤**:
```bash
rg "Prompt \{" codex-rs/core/tests --type rust -A 10
rg "Prompt::default" codex-rs/core/tests --type rust
```

**ä¿®æ”¹ç¤ºä¾‹**:
```rust
// âŒ ä¿®æ”¹å‰
let prompt = Prompt {
    input: vec![],
    tools: vec![],
    parallel_tool_calls: false,
    base_instructions_override: None,
    output_schema: None,
    reasoning_effort: None,
    reasoning_summary: None,
    previous_response_id: None,
    effective_parameters: Default::default(),
};

// âœ… ä¿®æ”¹å
let prompt = Prompt {
    input: vec![],
    tools: vec![],
    parallel_tool_calls: false,
    base_instructions_override: None,
    output_schema: None,
    // åˆ é™¤ 4 ä¸ªå­—æ®µ
};
```

#### Step 5.2: æ›´æ–°æµ‹è¯•ä¸­çš„ client.stream() è°ƒç”¨

```rust
// âŒ ä¿®æ”¹å‰
let stream = client.stream(&prompt).await?;

// âœ… ä¿®æ”¹å
let stream = client.stream(&prompt, None).await?;  // æµ‹è¯•ä¸­é€šå¸¸ä¸éœ€è¦ previous_response_id
```

#### Step 5.3: æ›´æ–° RequestContext mock

**å¦‚æœæµ‹è¯•ç›´æ¥æ„é€  RequestContext**:
```rust
let context = RequestContext {
    conversation_id: "test-123".to_string(),
    session_source: "Cli".to_string(),
    // âœ… æ–°å¢å­—æ®µ
    reasoning_effort: None,
    reasoning_summary: None,
    previous_response_id: None,
    effective_parameters: Default::default(),
};
```

**æˆ–è€…æä¾› helper å‡½æ•°**:
```rust
// In test utilities
impl RequestContext {
    pub fn test_default() -> Self {
        Self {
            conversation_id: "test-conv-id".to_string(),
            session_source: "Cli".to_string(),
            reasoning_effort: None,
            reasoning_summary: None,
            previous_response_id: None,
            effective_parameters: Default::default(),
        }
    }
}
```

---

## éªŒè¯æ¸…å•

### ç¼–è¯‘éªŒè¯

```bash
# Step 1: æ¸…ç†æ„å»ºç¼“å­˜
cargo clean -p codex-core

# Step 2: æ£€æŸ¥ç¼–è¯‘é”™è¯¯
cargo check -p codex-core 2>&1 | tee /tmp/check-errors.txt

# Step 3: å®Œæ•´æ„å»ºï¼ˆæ£€æŸ¥æ‰€æœ‰ä¾èµ–ï¼‰
cargo build 2>&1 | tee /tmp/build-errors.txt

# Step 4: æ£€æŸ¥æ˜¯å¦æœ‰é—æ¼çš„å­—æ®µè¯»å–
rg "prompt\.(reasoning_effort|reasoning_summary|previous_response_id|effective_parameters)" \
   codex-rs/core/src --type rust
```

### æµ‹è¯•éªŒè¯

```bash
# Step 1: å•å…ƒæµ‹è¯•
cargo test -p codex-core --lib 2>&1 | tee /tmp/unit-tests.txt

# Step 2: é›†æˆæµ‹è¯•
cargo test -p codex-core --test '*' 2>&1 | tee /tmp/integration-tests.txt

# Step 3: Adapter ç›¸å…³æµ‹è¯•ï¼ˆé‡ç‚¹ï¼‰
cargo test -p codex-core adapter 2>&1 | tee /tmp/adapter-tests.txt

# Step 4: æ‰€æœ‰æµ‹è¯•
cargo test --all-features 2>&1 | tee /tmp/all-tests.txt
```

### ä»£ç è´¨é‡æ£€æŸ¥

```bash
# Step 1: Clippy æ£€æŸ¥
just clippy 2>&1 | tee /tmp/clippy.txt

# Step 2: æ ¼å¼æ£€æŸ¥
just fmt

# Step 3: æ£€æŸ¥æ˜¯å¦æœ‰ unwrap (å¯èƒ½æ–°å¢)
rg "\.unwrap\(\)" codex-rs/core/src --type rust

# Step 4: æ£€æŸ¥æ˜¯å¦æœ‰æœªå¤„ç†çš„ TODO
rg "TODO|FIXME" codex-rs/core/src --type rust
```

### æ‰‹åŠ¨éªŒè¯

#### 1. æ£€æŸ¥æ‰€æœ‰ client.stream() è°ƒç”¨

```bash
# æŸ¥æ‰¾æ‰€æœ‰è°ƒç”¨ç‚¹
rg "\.stream\(&prompt" codex-rs/core/src --type rust -B 2 -A 2

# é¢„æœŸï¼šæ‰€æœ‰è°ƒç”¨éƒ½åº”è¯¥æœ‰ previous_response_id å‚æ•°
# stream(&prompt, previous_response_id)
```

#### 2. æ£€æŸ¥æ‰€æœ‰ Prompt æ„é€ 

```bash
# æŸ¥æ‰¾æ‰€æœ‰æ„é€ ç‚¹
rg "Prompt \{" codex-rs/core/src --type rust -A 10

# é¢„æœŸï¼šä¸åº”è¯¥åŒ…å« 4 ä¸ªåˆ é™¤çš„å­—æ®µ
# ä¸åº”è¯¥æœ‰ï¼šreasoning_effort, reasoning_summary,
#          previous_response_id, effective_parameters
```

#### 3. æ£€æŸ¥æ‰€æœ‰å­—æ®µè¯»å–

```bash
# åœ¨ adapter å®ç°ä¸­ï¼Œåº”è¯¥ä» context è¯»å–
rg "context\.(reasoning_effort|reasoning_summary|previous_response_id|effective_parameters)" \
   codex-rs/core/src/adapters --type rust

# ä¸åº”è¯¥ä» prompt è¯»å–ï¼ˆåº”è¯¥ä¸ºç©ºï¼‰
rg "prompt\.(reasoning_effort|reasoning_summary|previous_response_id|effective_parameters)" \
   codex-rs/core/src --type rust
```

### åŠŸèƒ½éªŒè¯

#### 1. è¿è¡Œ codex CLI

```bash
# åŸºæœ¬å¯¹è¯æµ‹è¯•
just codex "echo hello"

# Adapter è·¯å¾„æµ‹è¯•ï¼ˆå¦‚æœé…ç½®äº†è‡ªå®šä¹‰ adapterï¼‰
just codex "test adapter functionality"

# é•¿å¯¹è¯æµ‹è¯•ï¼ˆéªŒè¯æ€§èƒ½æ”¹è¿›ï¼‰
# åˆ›å»ºä¸€ä¸ªåŒ…å«å¤šè½®å¯¹è¯çš„æµ‹è¯•è„šæœ¬
```

#### 2. æ£€æŸ¥æ—¥å¿—

```bash
# å¯ç”¨è¯¦ç»†æ—¥å¿—
RUST_LOG=debug just codex "test" 2>&1 | grep -i "clone\|prompt\|context"

# é¢„æœŸï¼šä¸åº”è¯¥çœ‹åˆ° "cloning prompt" ç›¸å…³æ—¥å¿—
```

#### 3. æ€§èƒ½åŸºå‡†æµ‹è¯•ï¼ˆå¯é€‰ï¼‰

```bash
# å¯¹æ¯”ä¿®æ”¹å‰åçš„å†…å­˜åˆ†é…
# ä½¿ç”¨å·¥å…·å¦‚ valgrind, heaptrack ç­‰
# æˆ–è€…ç®€å•çš„æ—¶é—´æµ‹é‡

time just codex "run a long conversation"
```

---

## æ€§èƒ½å¯¹æ¯”

### å…‹éš†æˆæœ¬åˆ†æ

#### ä¿®æ”¹å‰ï¼ˆClone æ•´ä¸ª Promptï¼‰

| å¯¹è¯è§„æ¨¡ | æ¶ˆæ¯æ•°é‡ | Prompt å¤§å° | Clone æˆæœ¬ |
|---------|---------|------------|-----------|
| å°å¯¹è¯ | 10 æ¡ | ~5 KB | 5 KB |
| ä¸­å¯¹è¯ | 50 æ¡ | ~25 KB | 25 KB |
| å¤§å¯¹è¯ | 200 æ¡ | ~100 KB | 100 KB |
| è¶…å¤§å¯¹è¯ | 1000 æ¡ | ~500 KB | 500 KB |

**æ¯æ¬¡ turn çš„å¼€é”€**: 5-500 KB
**å…¸å‹å¯¹è¯ (3 turns, 50 æ¡æ¶ˆæ¯)**: 25 KB Ã— 3 = 75 KB

#### ä¿®æ”¹åï¼ˆClone 4 ä¸ªå­—æ®µï¼‰

| å­—æ®µ | ç±»å‹ | å¤§å°ä¼°ç®— |
|------|------|---------|
| `previous_response_id` | `Option<String>` | ~50 bytes |
| `effective_parameters` | `ModelParameters` | ~40 bytes (5 ä¸ª Option) |
| `reasoning_effort` | `Option<Enum>` | ~2 bytes |
| `reasoning_summary` | `Option<Enum>` | ~2 bytes |
| **æ€»è®¡** | - | **~100 bytes** |

**æ¯æ¬¡ turn çš„å¼€é”€**: ~100 bytesï¼ˆä¸éšå¯¹è¯å¢é•¿ï¼‰
**å…¸å‹å¯¹è¯ (3 turns)**: 100 bytes Ã— 3 = 300 bytes

---

## å­˜åœ¨ä¸è¶³

### 1. API ç ´åæ€§å˜æ›´

**é—®é¢˜**: `client.stream()` ç­¾åå˜æ›´

**å½±å“èŒƒå›´**:
- æ‰€æœ‰ç›´æ¥è°ƒç”¨ `ModelClient::stream()` çš„ä»£ç 
- æµ‹è¯•ä»£ç ä¸­çš„ mock è°ƒç”¨
- å¯èƒ½çš„å¤–éƒ¨ä¾èµ–ï¼ˆå¦‚æœ ModelClient æ˜¯å…¬å¼€ APIï¼‰

**ç¼“è§£æªæ–½**:
- è¿™æ˜¯å†…éƒ¨ APIï¼Œæ— å…¬å¼€ç”¨æˆ·
- ç¼–è¯‘æœŸå¼ºåˆ¶æ›´æ–°æ‰€æœ‰è°ƒç”¨ç‚¹
- æä¾›æ¸…æ™°çš„è¿ç§»æ–‡æ¡£ï¼ˆæœ¬ RFCï¼‰

### 2. å¤šå¤„è°ƒç”¨ç‚¹éœ€è¦æ›´æ–°

**é—®é¢˜**: `client.stream()` å¯èƒ½åœ¨å¤šå¤„è¢«è°ƒç”¨

**æœç´¢å‘½ä»¤ç¡®è®¤å½±å“**:
```bash
rg "\.stream\(&prompt\)" codex-rs --type rust
```

**ç¼“è§£æªæ–½**:
- ç¼–è¯‘å™¨ä¼šæ•è·æ‰€æœ‰é—æ¼çš„è°ƒç”¨ç‚¹
- é€ä¸€æ£€æŸ¥æ¯ä¸ªè°ƒç”¨ï¼Œç¡®ä¿ `previous_response_id` æ­£ç¡®ä¼ é€’
- è‡ªåŠ¨åŒ–æµ‹è¯•è¦†ç›–ä¸»è¦è·¯å¾„

### 3. æµ‹è¯•ä»£ç ä¿®æ”¹é‡å¤§

**é—®é¢˜**: æ‰€æœ‰æµ‹è¯•ä¸­çš„ Prompt æ„é€ éœ€è¦æ›´æ–°

**å½±å“**:
- å•å…ƒæµ‹è¯•ï¼š~20-30 å¤„
- é›†æˆæµ‹è¯•ï¼š~10-15 å¤„
- Mock ä»£ç ï¼š~5-10 å¤„

**ç¼“è§£æªæ–½**:
- æä¾› `Prompt::default()` ç®€åŒ–æµ‹è¯•æ„é€ 
- æä¾› `RequestContext::test_default()` helper
- é€ä¸ªæ–‡ä»¶ä¿®å¤ï¼Œç¡®ä¿æµ‹è¯•é€šè¿‡

### 4. Fallback è·¯å¾„å¤„ç†ä¸å®Œæ•´

**é—®é¢˜**: `WireApi::Responses` å’Œ `WireApi::Chat` è·¯å¾„å¯èƒ½éœ€è¦ `previous_response_id`

**å½“å‰çŠ¶æ€**:
- `stream_responses` æ¥æ”¶å‚æ•°ä½†æœªä½¿ç”¨
- `stream_chat_completions` ä¸æ”¯æŒ incremental mode

**åç»­ TODO**:
- è¯„ä¼° fallback è·¯å¾„æ˜¯å¦éœ€è¦ `previous_response_id`
- å¦‚æœéœ€è¦ï¼Œæ›´æ–° `ResponsesApiRequest` ç»“æ„
- æ·»åŠ ç›¸åº”çš„æµ‹è¯•è¦†ç›–

### 5. RequestContext å­—æ®µè¯­ä¹‰æ··åˆ

**é—®é¢˜**: RequestContext æ··åˆäº†ä¸¤ç±»æ•°æ®

| ç±»åˆ« | å­—æ®µ | ç”Ÿå‘½å‘¨æœŸ |
|------|------|---------|
| è¿è¡Œæ—¶ä¸Šä¸‹æ–‡ | conversation_id, session_source | Per-sessionï¼ˆç›¸å¯¹é™æ€ï¼‰ |
| æ¨¡å‹é…ç½® | reasoning_effort, reasoning_summary | Per-sessionï¼ˆç›¸å¯¹é™æ€ï¼‰ |
| ä¼šè¯çŠ¶æ€ | previous_response_id | Per-turnï¼ˆåŠ¨æ€ï¼‰ |
| é‡‡æ ·å‚æ•° | effective_parameters | Per-turnï¼ˆå¯èƒ½å˜åŒ–ï¼‰ |

**æ½œåœ¨é—®é¢˜**:
- è¯­ä¹‰ä¸å¤Ÿæ¸…æ™°ï¼šä»€ä¹ˆæ˜¯"è¯·æ±‚ä¸Šä¸‹æ–‡"ï¼Ÿ
- æœªæ¥æ‰©å±•æ—¶å¯èƒ½æ··å…¥æ›´å¤šä¸ç›¸å…³å­—æ®µ

**é•¿æœŸæ”¹è¿›æ–¹å‘**:
- å¯èƒ½è¿›ä¸€æ­¥æ‹†åˆ†ä¸º `RuntimeContext` + `ModelConfig` + `TurnState`
- ä½†å½“å‰æ–¹æ¡ˆå·²è¶³å¤Ÿæ¸…æ™°ï¼Œæš‚ä¸ä¼˜åŒ–

### 6. å†…å­˜å¤åˆ¶ä»ç„¶å­˜åœ¨

**é—®é¢˜**: è™½ç„¶ä¸ clone Promptï¼Œä½†ä»éœ€ clone 4 ä¸ªå­—æ®µ

**å½“å‰æˆæœ¬**:
- `previous_response_id`: `Option<String>` clone (~50 bytes)
- `effective_parameters`: `ModelParameters` clone (~40 bytes)
- `reasoning_effort`: `Option<Enum>` copy (~2 bytes)
- `reasoning_summary`: `Option<Enum>` copy (~2 bytes)

**è¿›ä¸€æ­¥ä¼˜åŒ–æ–¹å‘** (Phase 2):
- ä½¿ç”¨ `Arc<RequestContext>` é¿å…å­—æ®µ clone
- ä½†éœ€è¦è¯„ä¼° Arc çš„å¼€é”€ï¼ˆå¼•ç”¨è®¡æ•°ï¼‰
- å½“å‰ ~100 bytes clone å¯æ¥å—ï¼Œæš‚ä¸ä¼˜åŒ–

---

## æœªæ¥ä¼˜åŒ–

### Phase 2: Arc ä¼˜åŒ–ï¼ˆå¯é€‰ï¼‰

**å¦‚æœ RequestContext clone æˆä¸ºç“¶é¢ˆ**:

```rust
// ä¿®æ”¹ stream_with_adapter ç­¾å
pub async fn stream_with_adapter(
    &self,
    prompt: &Prompt,
    context: Arc<RequestContext>,  // âœ… ä½¿ç”¨ Arc
    provider: &ModelProviderInfo,
    adapter_name: &str,
    global_stream_idle_timeout: Option<u64>,
) -> Result<ResponseStream>

// åœ¨ client.stream() ä¸­æ„é€ 
let context = Arc::new(RequestContext {
    // ...
});
```

**ä¼˜ç¼ºç‚¹**:
- âœ… é›¶ cloneï¼ˆåªå¤åˆ¶ Arc æŒ‡é’ˆï¼‰
- âœ… å¤šä¸ª adapter æ–¹æ³•å…±äº«åŒä¸€ context
- âŒ Arc å¼•ç”¨è®¡æ•°å¼€é”€ï¼ˆatomic æ“ä½œï¼‰
- âŒ æ‰€æœ‰å­—æ®µå˜ä¸ºåªè¯»ï¼ˆå¦‚æœéœ€è¦ä¿®æ”¹éœ€è¦ cloneï¼‰

**å†³ç­–**: å½“å‰ ~100 bytes clone å¯æ¥å—ï¼Œæš‚ä¸å¼•å…¥ Arc

### Phase 3: è¿›ä¸€æ­¥åˆ†ç¦»ä¸Šä¸‹æ–‡ï¼ˆå¯é€‰ï¼‰

**å¦‚æœ RequestContext è¯­ä¹‰æ··ä¹±**:

```rust
#[derive(Debug, Clone)]
pub struct RuntimeContext {
    pub conversation_id: String,
    pub session_source: String,
}

#[derive(Debug, Clone)]
pub struct ModelConfig {
    pub reasoning_effort: Option<ReasoningEffortConfig>,
    pub reasoning_summary: Option<ReasoningSummaryConfig>,
}

#[derive(Debug, Clone)]
pub struct TurnState {
    pub previous_response_id: Option<String>,
    pub effective_parameters: ModelParameters,
}

// Adapter æ¥æ”¶ 3 ä¸ªç‹¬ç«‹ä¸Šä¸‹æ–‡
fn transform_request(
    &self,
    prompt: &Prompt,
    runtime: &RuntimeContext,
    model_config: &ModelConfig,
    turn_state: &TurnState,
    provider: &ModelProviderInfo,
) -> Result<JsonValue>;
```

**ä¼˜ç¼ºç‚¹**:
- âœ… è¯­ä¹‰æ›´æ¸…æ™°
- âœ… æ¯ä¸ªä¸Šä¸‹æ–‡èŒè´£å•ä¸€
- âŒ å‚æ•°æ•°é‡å¢åŠ ï¼ˆ4 ä¸ªä¸Šä¸‹æ–‡ï¼‰
- âŒ æ„é€ å¤æ‚åº¦å¢åŠ 

**å†³ç­–**: å½“å‰ RequestContext å·²è¶³å¤Ÿæ¸…æ™°ï¼Œæš‚ä¸æ‹†åˆ†

### Phase 4: ç¼“å­˜ RequestContextï¼ˆå¯é€‰ï¼‰

**å¦‚æœå‘ç°é‡å¤æ„é€  RequestContext**:

```rust
impl ModelClient {
    // ç¼“å­˜ session-level å­—æ®µ
    cached_context: Arc<Mutex<Option<RequestContext>>>,

    pub async fn stream(
        &self,
        prompt: &Prompt,
        previous_response_id: Option<String>,
    ) -> Result<ResponseStream> {
        // å¤ç”¨ç¼“å­˜çš„ contextï¼Œåªæ›´æ–° per-turn å­—æ®µ
        let mut cached = self.cached_context.lock().await;
        if let Some(ref mut ctx) = *cached {
            ctx.previous_response_id = previous_response_id;
            ctx.effective_parameters = self.resolve_parameters();
            return self.stream_with_adapter_cached(prompt, ctx.clone()).await;
        }

        // é¦–æ¬¡è°ƒç”¨ï¼Œæ„é€ å¹¶ç¼“å­˜
        // ...
    }
}
```

**ä¼˜ç¼ºç‚¹**:
- âœ… é¿å…é‡å¤æ„é€  session-level å­—æ®µ
- âŒ å¢åŠ å¤æ‚åº¦ï¼ˆç¼“å­˜å¤±æ•ˆã€çº¿ç¨‹å®‰å…¨ï¼‰
- âŒ å½“å‰æ„é€ æˆæœ¬ä½ï¼ˆ~100 bytesï¼‰ï¼Œä¼˜åŒ–æ”¶ç›Šå°

**å†³ç­–**: å½“å‰æ„é€ æˆæœ¬å¯æ¥å—ï¼Œæš‚ä¸ç¼“å­˜

---

## é™„å½•

### A. å…¨å±€æœç´¢å‘½ä»¤

**æŸ¥æ‰¾æ‰€æœ‰éœ€è¦ä¿®æ”¹çš„ä½ç½®**:

```bash
# 1. æŸ¥æ‰¾æ‰€æœ‰ Prompt æ„é€ 
rg "Prompt \{" codex-rs/core --type rust -A 10 > /tmp/prompt-constructions.txt

# 2. æŸ¥æ‰¾æ‰€æœ‰ client.stream() è°ƒç”¨
rg "\.stream\(&prompt" codex-rs/core --type rust -B 2 -A 2 > /tmp/stream-calls.txt

# 3. æŸ¥æ‰¾æ‰€æœ‰ä» prompt è¯»å– 4 å­—æ®µçš„ä½ç½®
rg "prompt\.(reasoning_effort|reasoning_summary|previous_response_id|effective_parameters)" \
   codex-rs/core --type rust > /tmp/prompt-field-reads.txt

# 4. æŸ¥æ‰¾æ‰€æœ‰ RequestContext æ„é€ 
rg "RequestContext \{" codex-rs/core --type rust -A 10 > /tmp/context-constructions.txt

# 5. æŸ¥æ‰¾æ‰€æœ‰ adapter.transform_request è°ƒç”¨
rg "\.transform_request\(" codex-rs/core --type rust -B 2 -A 2 > /tmp/transform-calls.txt
```

### B. æ‰¹é‡æ›¿æ¢è„šæœ¬ï¼ˆè°¨æ…ä½¿ç”¨ï¼‰

**ä»…ä½œå‚è€ƒï¼Œå»ºè®®æ‰‹åŠ¨é€ä¸ªæ£€æŸ¥**:

```bash
# åœ¨ gpt_openapi.rs ä¸­æ‰¹é‡æ›¿æ¢
sed -i.bak 's/prompt\.effective_parameters/context.effective_parameters/g' \
    codex-rs/core/src/adapters/gpt_openapi.rs

sed -i.bak 's/prompt\.previous_response_id/context.previous_response_id/g' \
    codex-rs/core/src/adapters/gpt_openapi.rs

sed -i.bak 's/prompt\.reasoning_effort/context.reasoning_effort/g' \
    codex-rs/core/src/adapters/gpt_openapi.rs

sed -i.bak 's/prompt\.reasoning_summary/context.reasoning_summary/g' \
    codex-rs/core/src/adapters/gpt_openapi.rs
```

**æ³¨æ„**:
- åŠ¡å¿…åœ¨æ‰§è¡Œå‰å¤‡ä»½æ–‡ä»¶
- æ‰§è¡Œåæ‰‹åŠ¨æ£€æŸ¥æ‰€æœ‰æ›¿æ¢æ˜¯å¦æ­£ç¡®
- å¯èƒ½ä¼šè¯¯æ›¿æ¢å…¶ä»– prompt ç›¸å…³ä»£ç 

### C. å½±å“èŒƒå›´æ€»ç»“è¡¨

| æ–‡ä»¶ | è¡Œæ•°èŒƒå›´ | æ”¹åŠ¨ç±»å‹ | ä¼˜å…ˆçº§ |
|------|---------|---------|-------|
| `client_common.rs` | 31-66 | åˆ é™¤ Prompt å­—æ®µ | ğŸ”´ é«˜ |
| `adapters/mod.rs` | 20-50, 431-460 | æ‰©å±• RequestContext + trait | ğŸ”´ é«˜ |
| `client.rs` | 180-240 | ä¿®æ”¹ stream() ç­¾å | ğŸ”´ é«˜ |
| `adapters/http.rs` | 69-136 | ç®€åŒ–å‚æ•° + åˆ é™¤ clone | ğŸ”´ é«˜ |
| `adapters/gpt_openapi.rs` | 427-470 | æ›´æ–°å­—æ®µè¯»å– | ğŸ”´ é«˜ |
| `codex.rs` | 1939-1968, è°ƒç”¨ç‚¹ | æ›´æ–° Prompt æ„é€  + stream è°ƒç”¨ | ğŸŸ¡ ä¸­ |
| `tests/**/*.rs` | å¤šå¤„ | æ›´æ–°æµ‹è¯•æ„é€ å’Œè°ƒç”¨ | ğŸŸ¢ ä½ |

### D. ç›¸å…³æ–‡æ¡£

- **Rust API Guidelines**: https://rust-lang.github.io/api-guidelines/
- **Performance Book**: https://nnethercote.github.io/perf-book/
- **codex-rs Architecture**: `codex-rs/CLAUDE.md`
- **Adapter System**: `codex-rs/docs/architecture/adapters.md`ï¼ˆå¦‚æœå­˜åœ¨ï¼‰

---

## æ€»ç»“

### å…³é”®å†³ç­–

1. âœ… **å¤ç”¨ RequestContext** - ç»Ÿä¸€"è¯·æ±‚ä¸Šä¸‹æ–‡"è¯­ä¹‰
2. âœ… **ä» Prompt å®Œå…¨ç§»é™¤ 4 å­—æ®µ** - æ¸…æ™°çš„èŒè´£åˆ†ç¦»
3. âœ… **client.stream() å¢åŠ å‚æ•°** - æ•°æ®æµæ›´æ¸…æ™°
4. âœ… **é›¶å¤§å¯¹è±¡ clone** - åªå¤åˆ¶ ~100 bytes å°å­—æ®µ

### é¢„æœŸæ”¶ç›Š

- **æ€§èƒ½æå‡**: 98-99.9% clone æˆæœ¬é™ä½
- **å¹´åº¦èŠ‚çœ**: ~300 GB â†’ ~300 MB å†…å­˜åˆ†é…
- **ä»£ç æ¸…æ™°åº¦**: Prompt ä¸“æ³¨æ¶ˆæ¯ï¼ŒRequestContext è´Ÿè´£é…ç½®
- **å¯æ‰©å±•æ€§**: æ–°å¢é…ç½®å‚æ•°åªéœ€ä¿®æ”¹ RequestContext

### å®æ–½é£é™©

- **API å˜æ›´**: `client.stream()` ç­¾åå˜æ›´ï¼ˆå†…éƒ¨ APIï¼Œå¯æ§ï¼‰
- **ä¿®æ”¹é‡**: 6-7 ä¸ªæ ¸å¿ƒæ–‡ä»¶ + æµ‹è¯•æ–‡ä»¶ï¼ˆä¸­ç­‰è§„æ¨¡ï¼‰
- **æµ‹è¯•è¦†ç›–**: éœ€è¦å…¨é¢æµ‹è¯• adapter è·¯å¾„

### ä¸‹ä¸€æ­¥

1. å®¡æŸ¥æœ¬ RFCï¼Œç¡®è®¤æŠ€æœ¯æ–¹æ¡ˆ
2. åˆ›å»º tracking issueï¼ˆå¦‚ GitHub Issueï¼‰
3. æŒ‰ç…§å®æ–½æ­¥éª¤é€æ­¥ä¿®æ”¹
4. æ¯ä¸ª Phase å®Œæˆåè¿è¡ŒéªŒè¯æ¸…å•
5. æ‰€æœ‰æµ‹è¯•é€šè¿‡ååˆå¹¶

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0
**æœ€åæ›´æ–°**: 2025-11-21
**çŠ¶æ€**: ç­‰å¾…å®¡æŸ¥
